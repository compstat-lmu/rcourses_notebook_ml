{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "We will use `mlr` to train the model. Additionally, we use parallelization to speed up the evaluation and tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(mlr)\n",
    "\n",
    "library(parallelMap)\n",
    "\n",
    "# Let one core remain to not completely slow down the system:\n",
    "parallelStartSocket(parallel::detectCores() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Splitting\n",
    "\n",
    "We use the prepared dataset `insurance_final.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With base R:\n",
    "insurance = read.csv(\"data/insurance_final.csv\")\n",
    "\n",
    "# Remove rows with missings:\n",
    "insurance = na.omit(insurance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatives to deleting data would be to impute the missing values with i.e. the mean or median. More advanced techniques here could be the EM algorithm.\n",
    "\n",
    "In order to finally evaluate the model on the new data from 2018 we create two index vectors which are used for training and a final holdout prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = insurance$year < 2018\n",
    "index_eval  = insurance$year == 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we delete all features which does not contain information or are not allowed to use for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = insurance[, -which(colnames(insurance) %in% c(\"id\", \"id2\", \"sex\", \"year\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Task\n",
    "\n",
    "To find a good regression model for `charges` we use all available features, with exception of `id`, `id2`, `sex`, and `year`, from the insurance dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = makeRegrTask(id = \"insurance_data\", target = \"charges\", data = insurance[index_train, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_ranger = makeLearner(\"regr.ranger\")\n",
    "learner_gbm = makeLearner(\"regr.gbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Resampling Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended but expensive:\n",
    "rdesc = makeResampleDesc(method = \"RepCV\", folds = 10, reps = 3)\n",
    "\n",
    "# We are using a 5-fold CV which is faster but not as accurate:\n",
    "rdesc = makeResampleDesc(method = \"CV\", iters = 5)\n",
    "\n",
    "# Fix instance for a later comparison:\n",
    "resample_instance = makeResampleInstance(desc = rdesc, task = task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_measures = list(mae, mse, rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_set_gbm = makeParamSet(\n",
    "  makeDiscreteParam(\"distribution\", values = c(\"gaussian\", \"laplace\", \"tdist\"))\n",
    "  , makeIntegerParam(\"n.trees\", lower = 100, upper = 3000)\n",
    "  , makeNumericParam(\"shrinkage\", lower = 0.0001, upper = 0.25)\n",
    "  , makeNumericParam(\"bag.fraction\", lower = 0.3, upper = 0.6)\n",
    "  , makeIntegerParam(\"interaction.depth\", lower = 1, upper = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tuning Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune_ctrl = makeTuneControlRandom(maxit = 200L)\n",
    "tune_ctrl = makeTuneControlRandom(maxit = 20L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the inner evaluation of a drawn parameter set we use 3-fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_resample_gbm = makeTuneWrapper(learner = learner_gbm, resampling = cv3, measures = mse, \n",
    "  par.set = par_set_gbm, control = tune_ctrl, show.info = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct the Benchmark/Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_res = benchmark(learners = list(\"regr.featureless\", \"regr.lm\", \"regr.rpart\", \"regr.ranger\"), task = task, \n",
    "  measures = used_measures, resamplings = resample_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_tune_res_gbm = resample(learner = learner_resample_gbm, task = task, resampling = resample_instance, extract = getTuneResult, \n",
    "  show.info = FALSE, measures = used_measures, keep.pred = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelStop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_res\n",
    "nested_tune_res_gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_task = makeRegrTask(id = \"insurance_data\", target = \"charges\", data = insurance)\n",
    "\n",
    "best_learner = lapply(X = nested_tune_res_gbm$extract, FUN = function (res) {\n",
    "  learner = makeLearner(id = paste0(\"y_\", round(res$y)), \"regr.gbm\")\n",
    "  learner = setHyperPars(learner = learner, par.vals = res$x)\n",
    "  return(learner)\n",
    "})\n",
    "final_holdout = makeFixedHoldoutInstance(train.inds = which(index_train), test.inds = which(index_eval), size = nrow(insurance))\n",
    "final_bm = benchmark(learners = best_learner, task = final_task, measures = used_measures, resamplings = final_holdout)\n",
    "final_bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize fit on 2018\n",
    "\n",
    "We will use `ggplot2` for visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visualize the best model w.r.t. the lowers mae:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_best_learner = which.max(getBMRAggrPerformances(final_bm, as.df = TRUE)$mae.test.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the model on the data without 2018 and create the plot for that year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_set = nested_tune_res_gbm$extract[[index_best_learner]]$x\n",
    "\n",
    "task = makeRegrTask(id = \"insurance_data\", target = \"charges\", data = insurance)\n",
    "learner = makeLearner(\"regr.gbm\")\n",
    "learner = setHyperPars(learner, par.vals = par_set)\n",
    "\n",
    "final_model = train(learner = learner, task = task, subset = index_train)\n",
    "\n",
    "pred_2018 = predict(final_model, newdata = insurance[index_eval, ])\n",
    "\n",
    "plot_data = pred_2018$data\n",
    "plot_data$Accuracy = cut(x = abs(plot_data$truth - plot_data$response), breaks = c(0, 500, 5000, Inf), labels = c(\"good\", \"ok\", \"critical\"))\n",
    "\n",
    "ggplot() +\n",
    "  geom_point(data = plot_data, mapping = aes(x = response, y = truth, color = Accuracy), alpha = 0.5) + \n",
    "  scale_color_brewer(palette = \"PuBu\") +\n",
    "  xlab(\"Predicted Premium\") + ylab(\"Real Claims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Final Model\n",
    "\n",
    "The last step is to build a model which uses all of the available data. This model should be used for further prediction tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model:\n",
    "task = makeRegrTask(id = \"insurance_data\", target = \"charges\", data = insurance)\n",
    "learner = makeLearner(\"regr.gbm\")\n",
    "learner = setHyperPars(learner, par.vals = nested_tune_res_gbm$extract[[index_best_learner]]$x)\n",
    "\n",
    "final_model = train(learner = learner, task = task)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
